{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 205,
   "id": "91aa8afa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import io\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from tinytag import TinyTag\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "id": "50a9b6dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_duration(row):\n",
    "    tag = TinyTag.get(file_obj=io.BytesIO(row[\"audio\"][\"bytes\"]))\n",
    "    return tag.duration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "id": "8e1db0b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 130 training parquet files\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading parquet files:   0%|          | 0/130 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading parquet files: 100%|██████████| 130/130 [00:59<00:00,  2.19it/s]\n"
     ]
    }
   ],
   "source": [
    "liepa_path = Path(\"../data/raw/liepa2/\")\n",
    "\n",
    "# Get all train parquet files\n",
    "train_files = sorted(liepa_path.glob(\"train-*.parquet\"))\n",
    "print(f\"Found {len(train_files)} training parquet files\")\n",
    "\n",
    "# Load and concatenate all training data\n",
    "dfs = []\n",
    "for file_path in tqdm(train_files, desc=\"Loading parquet files\"):\n",
    "    df = pd.read_parquet(file_path)\n",
    "    df[\"duration\"] = df.apply(get_duration, axis=1)\n",
    "    df[\"path\"] = df[\"audio\"].apply(lambda x: x[\"path\"])\n",
    "    df.drop(columns=[\"audio\"], inplace=True)\n",
    "    dfs.append(df)\n",
    "\n",
    "# Combine all dataframes\n",
    "full_df = pd.concat(dfs, ignore_index=True)\n",
    "full_df[\"sentence_len\"] = full_df[\"sentence\"].apply(len)\n",
    "full_df.sort_values(\"path\", inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "id": "fa47f0c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "parsing_rules = [\n",
    "    {\"L\": \"lossy\", \"R\": \"raw\"},\n",
    "    {\"R\": \"read\", \"S\": \"spontaneous\"},\n",
    "    {\n",
    "        \"A\": \"audiobook\",\n",
    "        \"D\": \"dictaphone\",\n",
    "        \"P\": \"phone\",\n",
    "        \"R\": \"radio\",\n",
    "        \"S\": \"studio\",\n",
    "        \"T\": \"TV\",\n",
    "    },\n",
    "    {\"F\": \"female\", \"M\": \"male\"},\n",
    "    {\"1\": \"0-12\", \"2\": \"13-17\", \"3\": \"18-25\", \"4\": \"26-60\", \"5\": \"60+\"},\n",
    "    {},\n",
    "    {},\n",
    "    {},\n",
    "]\n",
    "\n",
    "\n",
    "def parse_filename(filename):\n",
    "    filename = filename[:-4]\n",
    "    parts = filename.split(\"_\")\n",
    "    parts = [parts[0], parts[1][0], parts[1][1], parts[2][0], parts[2][1], *parts[3:]]\n",
    "    parts_standardized = [\n",
    "        parsing_rules[i].get(part, part) for i, part in enumerate(parts)\n",
    "    ]\n",
    "    return parts_standardized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "id": "7bba83bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "full_df[\n",
    "    [\n",
    "        \"lossiness\",\n",
    "        \"speech_type\",\n",
    "        \"source_type\",\n",
    "        \"speaker_gender\",\n",
    "        \"speaker_age\",\n",
    "        \"speaker_id\",\n",
    "        \"recording_id\",\n",
    "        \"sentence_id\",\n",
    "    ]\n",
    "] = full_df.path.apply(parse_filename).tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "id": "7d5cf202",
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_df = full_df[\n",
    "    (full_df[\"speech_type\"] == \"read\")\n",
    "    & (full_df[\"speaker_age\"].isin([\"18-25\", \"26-60\", \"60+\"]))\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "id": "8d889ecc",
   "metadata": {},
   "outputs": [],
   "source": [
    "speaker_counts_df = (\n",
    "    filtered_df\n",
    "    # calculate total count and duration per speaker\n",
    "    .groupby([\"speaker_gender\", \"speaker_id\"])\n",
    "    .agg(total_utterances=(\"sentence\", \"count\"), total_duration=(\"duration\", \"sum\"))\n",
    "    .reset_index()\n",
    "    .sort_values(by=[\"total_duration\"], ascending=False)\n",
    ")\n",
    "\n",
    "\n",
    "def select_speakers(speaker_counts_df, n_per_gender=10):\n",
    "    return speaker_counts_df.groupby(\"speaker_gender\").head(n_per_gender)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "198b1cfb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== n_per_gender = 15 ===\n",
      "  Minimum count of utterances for selected speakers: 718\n",
      "  Minimum total duration (s) for selected speakers: 2817.9312\n",
      "\n",
      "=== n_per_gender = 30 ===\n",
      "  Minimum count of utterances for selected speakers: 409\n",
      "  Minimum total duration (s) for selected speakers: 2527.8368\n",
      "\n",
      "=== n_per_gender = 90 ===\n",
      "  Minimum count of utterances for selected speakers: 409\n",
      "  Minimum total duration (s) for selected speakers: 1962.4496\n"
     ]
    }
   ],
   "source": [
    "selected_speakers = {}\n",
    "\n",
    "for n_per_gender in [15, 30, 90]:\n",
    "    selected_speakers_df = select_speakers(speaker_counts_df, n_per_gender)\n",
    "    selected_speakers[n_per_gender] = sorted(\n",
    "        selected_speakers_df[\"speaker_id\"].to_list()\n",
    "    )\n",
    "\n",
    "    assert all(\n",
    "        set(selected_speakers[n_per_gender]).issuperset(other_selected_speakers)\n",
    "        for _, other_selected_speakers in selected_speakers.items()\n",
    "    )\n",
    "    print(f\"\\n=== n_per_gender = {n_per_gender} ===\")\n",
    "    print(\n",
    "        f\"  Minimum count of utterances for selected speakers: \"\n",
    "        f\"{selected_speakers_df['total_utterances'].min()}\"\n",
    "    )\n",
    "    print(\n",
    "        f\"  Minimum total duration (s) for selected speakers: \"\n",
    "        f\"{selected_speakers_df['total_duration'].min()}\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f0386ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_duration_per_speaker(df, selected_speakers, seconds_per_speaker):\n",
    "    selected_df = df[df[\"speaker_id\"].isin(selected_speakers)]\n",
    "    sampled_dfs = []\n",
    "    for speaker_id in selected_speakers:\n",
    "        speaker_df = selected_df[selected_df[\"speaker_id\"] == speaker_id]\n",
    "        speaker_df = speaker_df.sample(\n",
    "            frac=1, random_state=42\n",
    "        )  # shuffle rows for randomness\n",
    "        cumulative_duration = (\n",
    "            speaker_df[\"duration\"].cumsum() - speaker_df[\"duration\"]\n",
    "        )  # include one more utterance\n",
    "        speaker_sampled_df = speaker_df[cumulative_duration <= seconds_per_speaker]\n",
    "        sampled_dfs.append(speaker_sampled_df)\n",
    "    return pd.concat(sampled_dfs, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "id": "c721e9df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== n_per_gender = 15 ===\n",
      "  Total sampled duration (minutes): 1350.790\n",
      "  Min/max duration per speaker (minutes): 45.00 / 45.10\n",
      "\n",
      "=== n_per_gender = 30 ===\n",
      "  Total sampled duration (minutes): 1351.553\n",
      "  Min/max duration per speaker (minutes): 22.50 / 22.63\n",
      "\n",
      "=== n_per_gender = 90 ===\n",
      "  Total sampled duration (minutes): 1354.763\n",
      "  Min/max duration per speaker (minutes): 7.50 / 7.61\n"
     ]
    }
   ],
   "source": [
    "for n_per_gender in [15, 30, 90]:\n",
    "    print(f\"\\n=== n_per_gender = {n_per_gender} ===\")\n",
    "    duration_per_speaker = 22.5 * 3600 / (n_per_gender * 2)\n",
    "    sample_df = sample_duration_per_speaker(\n",
    "        filtered_df, selected_speakers[n_per_gender], duration_per_speaker\n",
    "    )\n",
    "    print(f\"  Total sampled duration (minutes): {sample_df['duration'].sum() / 60:.3f}\")\n",
    "    print(\n",
    "        f\"  Min/max duration per speaker (minutes): \"\n",
    "        f\"{sample_df.groupby('speaker_id')['duration'].sum().min() / 60:.2f} / \"\n",
    "        f\"{sample_df.groupby('speaker_id')['duration'].sum().max() / 60:.2f}\"\n",
    "    )\n",
    "    sample_df.to_csv(f\"liepa_selected_{n_per_gender * 2}_speakers.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "msc-thesis",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
